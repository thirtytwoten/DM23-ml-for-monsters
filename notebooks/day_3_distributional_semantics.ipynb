{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1592abea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593afce2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributional Semantics: Representing the Meaning of Words  with Numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19051b59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "So far we haven't talked through representing the **meaning** of language with statistical methods.\n",
    "\n",
    "We *have* done machine learning. N-gram models learn probabilistic rules for generating sentences based on statistical patterns inferred from the data. But this models might seem shallow in some way, because it focuses on form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505e931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How might we go about learning representations of the meaning of words in our corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8871d272",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "corpus = \"\"\"By this liberty they entered into a very laudable emulation to do all of them \\\n",
    "what they saw did please one. If any of the gallants or ladies should say, Let us drink, \\\n",
    "they would all drink.  If any one of them said, Let us play, they all played.  If one said, \\\n",
    "Let us go a-walking into the fields they went all.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04241e35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In **distributional semantics***, the basic intuition is that similar words appear in similar contexts.\n",
    "\n",
    "Great. How do we *measure* the similarity of contexts? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50303465",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It might help at this point to distinguish two kinds of meaning relations between words.\n",
    "\n",
    "**syntagmatic** relationships between words arise because of a sequential ordering. Words in a sentence form a syntagm. \n",
    "* think of the word *syntax*, which links words with different functions in a sentence\n",
    "\n",
    "This contrasts with **paradigmatic** relationships. Words in a **paradigm** are related because they may be substituted for one another in certain contexts. \n",
    "* think of a verb tense paradigm or a noun declension in learning a new languages\n",
    "* these words can go in the same \"slot\" in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ad9ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: syntagmatic or paradigmatic?\n",
    "\n",
    "flower - leaf\n",
    "\n",
    "of - the\n",
    "\n",
    "ice - cream\n",
    "\n",
    "word - sick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1da09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a look at the guts of n-gram model from yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c3037b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('by', 'this'), ('this', 'liberty'), ('liberty', 'they'), ('they', 'entered'), ('entered', 'into'), ('into', 'a'), ('a', 'very'), ('very', 'laudable'), ('laudable', 'emulation'), ('emulation', 'to')]\n"
     ]
    }
   ],
   "source": [
    "def ngrams(tokenized_corpus, n):\n",
    "    # get the ngrams for a corpus\n",
    "    n_grams = []\n",
    "    for i in range(n-1, len(tokenized_corpus)): \n",
    "        n_grams.append(tuple(tokenized_corpus[i-(n-1):i+1]))\n",
    "    return n_grams\n",
    "\n",
    "def ngram_tokenize(text):\n",
    "    # tokenize a text for an ngram model\n",
    "    tokenized_corpus = re.sub(r'(\\w)([.,?!;:])', r'\\1 \\2', corpus) \n",
    "    tokenized_corpus = tokenized_corpus.split()\n",
    "    tokenized_corpus = [word.lower() for word in tokenized_corpus]\n",
    "    return tokenized_corpus\n",
    "\n",
    "# print the first 10 tri-grams\n",
    "print(ngrams(ngram_tokenize(corpus), 2)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c48edb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'of': 1, 'drink': 1, 'played': 1, '.': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram conditional frequency distribution\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(ngrams(ngram_tokenize(corpus), 2))\n",
    "cfd['all']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89a55e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question : What kinds of relationships between words do N-gram models learn? Syntagmatic or paradigmatic? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd022cc6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### You can write your notes here\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "####\n",
    "####\n",
    "\n",
    "####\n",
    "####\n",
    "####\n",
    "\n",
    "####\n",
    "####\n",
    "####\n",
    "\n",
    "**Hint**: the numbers encode a relationship between two words. Which words? How are those words related?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24954d77",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "N-gram models explicitly encode syntagmatic (sequence-oriented) relationships. The probabilities represent relationships between two words in a sequence. If the frequency is very high, then they occur together very often, but they might not have a semantically similar meaning. (e.g. `let us`)\n",
    "\n",
    "But they do capture a kind of paradigmatic relationship as well, if not numerically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdabc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All of the words that end up in the frequency distribution for a single word have something in common. They do occur in the same \"slot\" in the sentence. Often this leads to them having semantic commonalites.\n",
    "\n",
    "We can see this for the frequency distribution of 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc828f27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'drink': 1, 'play': 1, 'go': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd['us']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c66a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The words in the frequency distribution for *us* form a meaningful paradigm! They are all active verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81693917",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "But in the n-gram model there's still no numerical representation of similarity between two arbitrary words.\n",
    "\n",
    "### perhaps we could imagine one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16447600",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "If two words occur in the same frequency distribution, they are similar. If they don't, they are dissimilar. \n",
    "\n",
    "Maybe if they occur in many of the same frequency distributions, they are more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123af660",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they contexts:  dict_items([('a-walking', 1)])\n",
      "us contexts:  dict_items([(',', 1)])\n"
     ]
    }
   ],
   "source": [
    "# illustrate this \n",
    "print(\"they contexts: \", cfd['go'].items()) \n",
    "print(\"us contexts: \", cfd['play'].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50ba20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our corpus is very small. *go* and *play* only occur in one context (us). but *go* and *played* occur in another (\"all\"). If we had lemmatized our corpus (collapsed different forms of the same word(, then the lemmas GO and PLAY would share two contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f588a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words that don't share contexts are dissimilar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26eed328",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they contexts:  dict_items([('or', 1)])\n",
      "us contexts:  dict_items([('of', 1), ('drink', 1), ('played', 1), ('.', 1)])\n"
     ]
    }
   ],
   "source": [
    "# illustrate this \n",
    "print(\"they contexts: \", cfd['gallants'].items()) \n",
    "print(\"us contexts: \", cfd['all'].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d83d87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So our whole idea of  \"semantic similarity\" is based on shared context. As such, its totally dependent on our definition of context. What counts as a context? What counts as the same context? Our answers to these questions can change everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b52210",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing co-occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2accae1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Perhaps this is more intuitive as a table. We make a row in the table for each word type, and a column for all of the contexts. Then, we compare it to the contexts of another word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203f542",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is a function to convert our cfd to a large Pandas dataframe. Pandas is a super useful package for working with and organizing data, but we are just using it here for visualization purposes. You can ignore this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc273f92",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "turn a cfd into a big dataframe with rows and columns labeled for easy visualization\n",
    "\"\"\"\n",
    "\n",
    "def cfd_to_dataframe(cfd):\n",
    "    \n",
    "    # We put our rows and columns in order.\n",
    "    # For now, our rows are the same as our columns:\n",
    "    # All target words are also context words, and vice versa.\n",
    "    # But that doesn't have to be the case.\n",
    "    targetlist = sorted(cfd.conditions())\n",
    "    contextlist = sorted(list(set(c for t in cfd.conditions() \n",
    "                                  for c in cfd[t].keys())))\n",
    "\n",
    "    # make a numpy matrix out of our sparse dictionary entries\n",
    "    rows = [ ]\n",
    "    for t in targetlist:\n",
    "        # for context words c for which we don't have an entry,\n",
    "        # the ConditionalFreqDist returns zero\n",
    "        rows.append( [cfd[t][c] for c in contextlist])\n",
    "\n",
    "    count_matrix = np.array(rows)\n",
    "    count_matrix\n",
    "\n",
    "    # add a space so that pandas doesn't get confused that our rows and columns have the same name\n",
    "    contextlist1 = [w+ \" \" for w in contextlist] \n",
    "    \n",
    "    # make the pandas dataframe\n",
    "    df =  pd.DataFrame.from_records(data=count_matrix, index=targetlist, columns = [c+\" \" for c in contextlist1])\n",
    "    df.index.name = 'target'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbbd01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Running the function on our n-gram cfd gives another view on the frequency distribution, with all the zeros filed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb1d731",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>a</th>\n",
       "      <th>a-walking</th>\n",
       "      <th>all</th>\n",
       "      <th>any</th>\n",
       "      <th>did</th>\n",
       "      <th>do</th>\n",
       "      <th>drink</th>\n",
       "      <th>emulation</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>them</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "      <th>to</th>\n",
       "      <th>us</th>\n",
       "      <th>very</th>\n",
       "      <th>went</th>\n",
       "      <th>what</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a-walking</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drink</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emulation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entered</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fields</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gallants</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ladies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laudable</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberty</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>played</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ,    .    a    a-walking    all    any    did    do    drink    \\\n",
       "target                                                                      \n",
       ",            0    0    0            0      0      0      0     0        0   \n",
       ".            0    0    0            0      0      0      0     0        0   \n",
       "a            0    0    0            0      0      0      0     0        0   \n",
       "a-walking    0    0    0            0      0      0      0     0        0   \n",
       "all          0    1    0            0      0      0      0     0        1   \n",
       "any          0    0    0            0      0      0      0     0        0   \n",
       "by           0    0    0            0      0      0      0     0        0   \n",
       "did          0    0    0            0      0      0      0     0        0   \n",
       "do           0    0    0            0      1      0      0     0        0   \n",
       "drink        1    1    0            0      0      0      0     0        0   \n",
       "emulation    0    0    0            0      0      0      0     0        0   \n",
       "entered      0    0    0            0      0      0      0     0        0   \n",
       "fields       0    0    0            0      0      0      0     0        0   \n",
       "gallants     0    0    0            0      0      0      0     0        0   \n",
       "go           0    0    0            1      0      0      0     0        0   \n",
       "if           0    0    0            0      0      2      0     0        0   \n",
       "into         0    0    1            0      0      0      0     0        0   \n",
       "ladies       0    0    0            0      0      0      0     0        0   \n",
       "laudable     0    0    0            0      0      0      0     0        0   \n",
       "let          0    0    0            0      0      0      0     0        0   \n",
       "liberty      0    0    0            0      0      0      0     0        0   \n",
       "of           0    0    0            0      0      0      0     0        0   \n",
       "one          0    1    0            0      0      0      0     0        0   \n",
       "or           0    0    0            0      0      0      0     0        0   \n",
       "play         1    0    0            0      0      0      0     0        0   \n",
       "played       0    1    0            0      0      0      0     0        0   \n",
       "please       0    0    0            0      0      0      0     0        0   \n",
       "said         2    0    0            0      0      0      0     0        0   \n",
       "saw          0    0    0            0      0      0      1     0        0   \n",
       "say          1    0    0            0      0      0      0     0        0   \n",
       "should       0    0    0            0      0      0      0     0        0   \n",
       "the          0    0    0            0      0      0      0     0        0   \n",
       "them         0    0    0            0      0      0      0     0        0   \n",
       "they         0    0    0            0      1      0      0     0        0   \n",
       "this         0    0    0            0      0      0      0     0        0   \n",
       "to           0    0    0            0      0      0      0     1        0   \n",
       "us           0    0    0            0      0      0      0     0        1   \n",
       "very         0    0    0            0      0      0      0     0        0   \n",
       "went         0    0    0            0      1      0      0     0        0   \n",
       "what         0    0    0            0      0      0      0     0        0   \n",
       "would        0    0    0            0      1      0      0     0        0   \n",
       "\n",
       "           emulation    ...  the    them    they    this    to    us    \\\n",
       "target                  ...                                              \n",
       ",                    0  ...      0       0       2       0     0     0   \n",
       ".                    0  ...      0       0       0       0     0     0   \n",
       "a                    0  ...      0       0       0       0     0     0   \n",
       "a-walking            0  ...      0       0       0       0     0     0   \n",
       "all                  0  ...      0       0       0       0     0     0   \n",
       "any                  0  ...      0       0       0       0     0     0   \n",
       "by                   0  ...      0       0       0       1     0     0   \n",
       "did                  0  ...      0       0       0       0     0     0   \n",
       "do                   0  ...      0       0       0       0     0     0   \n",
       "drink                0  ...      0       0       0       0     0     0   \n",
       "emulation            0  ...      0       0       0       0     1     0   \n",
       "entered              0  ...      0       0       0       0     0     0   \n",
       "fields               0  ...      0       0       1       0     0     0   \n",
       "gallants             0  ...      0       0       0       0     0     0   \n",
       "go                   0  ...      0       0       0       0     0     0   \n",
       "if                   0  ...      0       0       0       0     0     0   \n",
       "into                 0  ...      1       0       0       0     0     0   \n",
       "ladies               0  ...      0       0       0       0     0     0   \n",
       "laudable             1  ...      0       0       0       0     0     0   \n",
       "let                  0  ...      0       0       0       0     0     3   \n",
       "liberty              0  ...      0       0       1       0     0     0   \n",
       "of                   0  ...      1       2       0       0     0     0   \n",
       "one                  0  ...      0       0       0       0     0     0   \n",
       "or                   0  ...      0       0       0       0     0     0   \n",
       "play                 0  ...      0       0       0       0     0     0   \n",
       "played               0  ...      0       0       0       0     0     0   \n",
       "please               0  ...      0       0       0       0     0     0   \n",
       "said                 0  ...      0       0       0       0     0     0   \n",
       "saw                  0  ...      0       0       0       0     0     0   \n",
       "say                  0  ...      0       0       0       0     0     0   \n",
       "should               0  ...      0       0       0       0     0     0   \n",
       "the                  0  ...      0       0       0       0     0     0   \n",
       "them                 0  ...      0       0       0       0     0     0   \n",
       "they                 0  ...      0       0       0       0     0     0   \n",
       "this                 0  ...      0       0       0       0     0     0   \n",
       "to                   0  ...      0       0       0       0     0     0   \n",
       "us                   0  ...      0       0       0       0     0     0   \n",
       "very                 0  ...      0       0       0       0     0     0   \n",
       "went                 0  ...      0       0       0       0     0     0   \n",
       "what                 0  ...      0       0       1       0     0     0   \n",
       "would                0  ...      0       0       0       0     0     0   \n",
       "\n",
       "           very    went    what    would    \n",
       "target                                      \n",
       ",               0       0       0        0  \n",
       ".               0       0       0        0  \n",
       "a               1       0       0        0  \n",
       "a-walking       0       0       0        0  \n",
       "all             0       0       0        0  \n",
       "any             0       0       0        0  \n",
       "by              0       0       0        0  \n",
       "did             0       0       0        0  \n",
       "do              0       0       0        0  \n",
       "drink           0       0       0        0  \n",
       "emulation       0       0       0        0  \n",
       "entered         0       0       0        0  \n",
       "fields          0       0       0        0  \n",
       "gallants        0       0       0        0  \n",
       "go              0       0       0        0  \n",
       "if              0       0       0        0  \n",
       "into            0       0       0        0  \n",
       "ladies          0       0       0        0  \n",
       "laudable        0       0       0        0  \n",
       "let             0       0       0        0  \n",
       "liberty         0       0       0        0  \n",
       "of              0       0       0        0  \n",
       "one             0       0       0        0  \n",
       "or              0       0       0        0  \n",
       "play            0       0       0        0  \n",
       "played          0       0       0        0  \n",
       "please          0       0       0        0  \n",
       "said            0       0       0        0  \n",
       "saw             0       0       0        0  \n",
       "say             0       0       0        0  \n",
       "should          0       0       0        0  \n",
       "the             0       0       0        0  \n",
       "them            0       0       1        0  \n",
       "they            0       1       0        1  \n",
       "this            0       0       0        0  \n",
       "to              0       0       0        0  \n",
       "us              0       0       0        0  \n",
       "very            0       0       0        0  \n",
       "went            0       0       0        0  \n",
       "what            0       0       0        0  \n",
       "would           0       0       0        0  \n",
       "\n",
       "[41 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd_to_dataframe(cfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e505d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That's all it took!\n",
    "\n",
    "This is a co-occurence based distributional semantic model! \n",
    "\n",
    "The cool thing about representing words like this is that we can think of the words and their relationships to each other spatially.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a737e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each row is a **vector** representing that word. Each column is a dimension. \n",
    "\n",
    "I think of vectors as points in space. A point in 3-D Euclidean space has 3 coordinates:\n",
    "\n",
    "    (x,y,z)\n",
    "    \n",
    "A point in N-dimensional space has N coordinates. You can read a word vector as a long list of coordinates, with each value giving the location of the point along that dimension. N-dimensional space is much harder to visualize, but it works exactly the same way as 2 and 3-D space in terms of calculating distances and so on. \n",
    "\n",
    "    (x, y, z, ....) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c9a72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "**Prompt**: How many dimensions does our Theleme-space have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45c02f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words that have similar meanings occur in similar contexts.\n",
    "Words in similar contexts are near together in semantic space.\n",
    "\n",
    "Ergo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0877d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Words that are similar in meaning are near together in semantic space!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb65ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Most of the time, people talk about similarity in semantic space in terms of cosine, which measures the angle between two vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799e209",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../img/cosinesimilarity.png\" alt=\"Alternative text\" width=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6318fc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we measured the absolute distance (Euclidean distance), we would end up with differences where we don't want them. Vectors for very common words would be very long and thus very far apart from vectors for infrquent words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc90846",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"../img/sadapple.png\" alt=\"Alternative text\" width=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77188e0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**question:** why would frequent words have longer vectors? (by length i mean, how far away from the origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df45998",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is the formula for cosine similarity\n",
    "\n",
    "$\\text{Cosine Similarity} = \\cos(\\theta) = \\frac{(A \\cdot B)}{ (||A|| \\cdot ||B||)} = \\frac{\\sum_{i=1}^{n} A_i \\cdot B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} B_i^2}}$\n",
    "\n",
    "The numerator is the dot product (a linear algebra operation that measures similarity), and the bottom is a normalization term that gets rid of differences due to magnitude (aka frequency).\n",
    "\n",
    "We will share another notebook that introduces linear algebra and goes through the derivation of cosine. \n",
    "\n",
    "Cosine of two angles varies between -1 and 1. As the angle between two vectors gets smaller, the cosine gets closer to one. Similar words have a high cosine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65488bca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rewind: How did we make this giant graph?\n",
    "\n",
    "We have something very like the co-occurrence model already with the n-gram frequency distribution, just represented in a different way. \n",
    "\n",
    "The goal is to build a giant table, where each row contains a numeric representation of a word. \n",
    "There will be one row and one column for each word **type** in our corpus. \n",
    "\n",
    "Each row is a **vector**: a numerical representation of the meaning of the word in that row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99275d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What counts as context? Differences between N-gram modeling and distributional semantics\n",
    "\n",
    "The idea of context is different in these paradigms. What's our idea of context in an n-gram model?\n",
    "\n",
    "What is the idea of context we want for thinking about word meaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e407e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to look at words on both sides of our target word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffc272",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing: Tokenization, Lemmatization and Normalization\n",
    "\n",
    "There are also different preprocessing concerns. We might want to remove stop words and limit low frequency words, which we wouldn't want to do with n-gram models.\n",
    "\n",
    "\n",
    "**Tokenization:** Separate into contexts, words.\n",
    "\n",
    "**(Normalization):** Multiple spellings, capitalization.\n",
    "\n",
    "**(Lemmatization):** Different forms of a word collapse into one.\n",
    "\n",
    "**Stop-word removal:** Discarding common words.\n",
    "\n",
    "**Frequency Limits:** Discard very infrequent words.\n",
    "\n",
    "\n",
    "We'll do all of these things in one go. We are using the nltk lemmatizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4171e1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    \n",
    "    # discard punctuation\n",
    "    corpus = re.sub(r'[\\.,]', '', corpus)\n",
    "\n",
    "    # tokenization\n",
    "    words = nltk.word_tokenize(corpus)\n",
    "    \n",
    "    # normalization\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # stemming - mpt necessary for small corpus\n",
    "    # stemmer = PorterStemmer()\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    \n",
    "    # stop-word-removal\n",
    "    stopwords = set('for a of the and to in'.split())\n",
    "    words = list(filter(lambda x: x not in stopwords, words))\n",
    "    \n",
    "    # a heftier stop list (unnecessary for small example) but you might want it at some point\n",
    "    # nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    # discard low-frequency words\n",
    "    # don't need this for small corpus\n",
    "    # wordcounts = Counter(words)\n",
    "    # frequency_threshold = 20\n",
    "    # words = list(w for w in wordcounts if wordcounts[w] >= frequency_threshold)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13360931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by',\n",
       " 'this',\n",
       " 'liberty',\n",
       " 'they',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'very',\n",
       " 'laudable',\n",
       " 'emulation',\n",
       " 'do']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(corpus)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4a17f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counting contexts\n",
    "\n",
    "Yesterday we used a left only version of context because we were generating text from left to right.\n",
    "Distributional models typically use a context window on both sides of the target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925e61bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def context_counts(words, window_size=1):\n",
    "    \n",
    "    context_counts = nltk.ConditionalFreqDist()\n",
    "    \n",
    "    # iterate over the whole corpus, but\n",
    "    # start a little to the right and end a little to the left\n",
    "    # so we don't have to worry about (literal) edge cases\n",
    "\n",
    "    for i in range(window_size+1, len(words)-window_size): \n",
    "        \n",
    "        # i is the index of the target word. \n",
    "        target = words[i]\n",
    "        \n",
    "        # we want to get the words to the left within the window \n",
    "        # and then do the same with the words to the right within the window\n",
    "        left_context_words = words[i-1-window_size:i-1]\n",
    "        right_context_words = words[i+1:i + 1 + window_size ]\n",
    "        \n",
    "        # and add them to the context count\n",
    "        for context in (left_context_words + right_context_words):\n",
    "            context_counts[target][context] += 1\n",
    "        \n",
    "        #break\n",
    "        \n",
    "    return context_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18f2a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It may be helpful to compare this function with the one that builds the frequency distribution in our ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76507642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "context_counts = context_counts(preprocess(corpus), window_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474246d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have a data structure containing context counts for each word. Our ConditionalFreqDist has our words as our conditions, and contexts as its outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20580eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can think of this as, the word \"play\" potentially occurs in four contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1177b80",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('said', 1), ('let', 1), ('they', 1), ('all', 1)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_counts[\"play\"].items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78d68e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use the function defined above  to visualize the cfd as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "489344fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a-walking</th>\n",
       "      <th>all</th>\n",
       "      <th>any</th>\n",
       "      <th>by</th>\n",
       "      <th>did</th>\n",
       "      <th>do</th>\n",
       "      <th>drink</th>\n",
       "      <th>emulation</th>\n",
       "      <th>entered</th>\n",
       "      <th>field</th>\n",
       "      <th>...</th>\n",
       "      <th>say</th>\n",
       "      <th>should</th>\n",
       "      <th>them</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "      <th>u</th>\n",
       "      <th>very</th>\n",
       "      <th>went</th>\n",
       "      <th>what</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a-walking</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drink</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emulation</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entered</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gallant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laudable</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>played</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           a-walking    all    any    by    did    do    drink    emulation    \\\n",
       "target                                                                          \n",
       "a-walking            0      0      0     0      0     0        0            0   \n",
       "all                  0      0      0     0      0     0        2            1   \n",
       "any                  0      1      0     0      0     0        1            0   \n",
       "did                  0      0      0     0      0     0        0            0   \n",
       "do                   0      1      0     0      0     0        0            0   \n",
       "drink                0      0      1     0      0     0        0            0   \n",
       "emulation            0      1      0     0      0     1        0            0   \n",
       "entered              0      0      0     0      0     0        0            0   \n",
       "field                1      0      0     0      0     0        0            0   \n",
       "gallant              0      0      0     0      0     0        0            0   \n",
       "go                   1      0      0     0      0     0        0            0   \n",
       "if                   0      2      2     0      1     0        0            0   \n",
       "into                 0      0      0     0      0     0        0            0   \n",
       "lady                 0      0      1     0      0     0        0            0   \n",
       "laudable             0      0      0     0      0     1        0            1   \n",
       "let                  0      0      0     0      0     0        1            0   \n",
       "one                  0      1      1     0      1     0        1            0   \n",
       "or                   0      0      1     0      0     0        0            0   \n",
       "play                 0      1      0     0      0     0        0            0   \n",
       "played               0      0      0     0      0     0        0            0   \n",
       "please               0      0      0     0      0     0        0            0   \n",
       "said                 0      0      1     0      0     0        0            0   \n",
       "saw                  0      0      0     0      1     0        0            0   \n",
       "say                  0      0      0     0      0     0        0            0   \n",
       "should               0      0      0     0      0     0        0            0   \n",
       "them                 0      0      1     0      0     1        0            1   \n",
       "they                 1      4      0     1      1     0        0            0   \n",
       "u                    1      0      0     0      0     0        1            0   \n",
       "very                 0      0      0     0      0     0        0            1   \n",
       "what                 0      1      0     0      0     1        0            0   \n",
       "would                0      1      0     0      0     0        2            0   \n",
       "\n",
       "           entered    field    ...  say    should    them    they    this    \\\n",
       "target                         ...                                            \n",
       "a-walking          0        1  ...      0         0       0       0       0   \n",
       "all                0        0  ...      0         0       1       1       0   \n",
       "any                0        0  ...      0         0       1       0       0   \n",
       "did                0        0  ...      0         0       0       1       0   \n",
       "do                 0        0  ...      0         0       1       0       0   \n",
       "drink              0        0  ...      1         0       0       2       0   \n",
       "emulation          0        0  ...      0         0       0       0       0   \n",
       "entered            0        0  ...      0         0       0       0       1   \n",
       "field              0        0  ...      0         0       0       1       0   \n",
       "gallant            0        0  ...      0         0       0       0       0   \n",
       "go                 0        0  ...      0         0       0       0       0   \n",
       "if                 0        0  ...      0         0       0       1       0   \n",
       "into               0        1  ...      0         0       0       2       0   \n",
       "lady               0        0  ...      1         1       0       0       0   \n",
       "laudable           1        0  ...      0         0       0       0       0   \n",
       "let                0        0  ...      0         1       1       0       0   \n",
       "one                0        0  ...      0         0       1       0       0   \n",
       "or                 0        0  ...      0         1       0       0       0   \n",
       "play               0        0  ...      0         0       0       1       0   \n",
       "played             0        0  ...      0         0       0       1       0   \n",
       "please             0        0  ...      0         0       0       1       0   \n",
       "said               0        0  ...      0         0       0       0       0   \n",
       "saw                0        0  ...      0         0       1       0       0   \n",
       "say                0        0  ...      0         0       0       0       0   \n",
       "should             0        0  ...      1         0       0       0       0   \n",
       "them               0        0  ...      0         0       0       1       0   \n",
       "they               1        0  ...      0         0       1       0       1   \n",
       "u                  0        0  ...      1         1       1       2       0   \n",
       "very               1        0  ...      0         0       0       1       0   \n",
       "what               0        0  ...      0         0       0       1       0   \n",
       "would              0        0  ...      0         0       0       0       0   \n",
       "\n",
       "           u    very    went    what    would    \n",
       "target                                           \n",
       "a-walking    1       0       0       0        0  \n",
       "all          1       0       0       1        0  \n",
       "any          0       0       0       0        0  \n",
       "did          0       0       0       1        0  \n",
       "do           0       1       0       0        0  \n",
       "drink        0       0       0       0        2  \n",
       "emulation    0       1       0       0        0  \n",
       "entered      0       1       0       0        0  \n",
       "field        0       0       1       0        0  \n",
       "gallant      0       0       0       0        0  \n",
       "go           0       0       0       0        0  \n",
       "if           0       0       0       0        1  \n",
       "into         1       1       0       0        0  \n",
       "lady         0       0       0       0        0  \n",
       "laudable     0       0       0       0        0  \n",
       "let          3       0       0       0        0  \n",
       "one          0       0       0       0        0  \n",
       "or           0       0       0       0        0  \n",
       "play         0       0       0       0        0  \n",
       "played       0       0       0       0        0  \n",
       "please       0       0       0       0        0  \n",
       "said         2       0       0       0        0  \n",
       "saw          0       0       0       1        0  \n",
       "say          1       0       0       0        0  \n",
       "should       0       0       0       0        0  \n",
       "them         0       0       0       1        0  \n",
       "they         2       0       1       0        1  \n",
       "u            0       0       0       0        0  \n",
       "very         0       0       0       0        0  \n",
       "what         0       0       0       0        0  \n",
       "would        1       0       0       0        0  \n",
       "\n",
       "[31 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd_to_dataframe(context_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae51179",
   "metadata": {},
   "source": [
    "# Comparing words\n",
    "\n",
    "The most exciting thing about representing words as points in space is that it gives us access to geometric notions like distance to compare signs.\n",
    "\n",
    "Look again at the table. Words that occur in the same contexts have positive values along the same dimensions. This results in them being near to one another in space. I'll say that again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685a1c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"play\" shares contexts with \"drink\", making it similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f2d3c1e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('said', 1), ('let', 1), ('they', 1), ('all', 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_counts[\"play\"].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e34ed07",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'they': 2, 'would': 2, 'say': 1, 'let': 1, 'if': 1, 'any': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_counts[\"drink\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7b8b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It doesn't share any contexts with \"gallant\", making them *maximally dissimilar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05fb5dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'one': 1, 'if': 1, 'or': 1, 'lady': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_counts[\"gallant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68335004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The conditional frequency distribution for \"play\" is one way to represent the sparse row vector for the word \"go\". It has positive values for \",\", \"let\", \"a-walking\", and \"into\", and zero values everywhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50829b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Theleme Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849b967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our cfd vector representations are sparse. To do linear algebra operations on them---multiplication and comparison, we need to represent them as a whole vector. We use Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c660e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's a function to make a dictionary of numpy vectors out of our cfd. It's just a utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b5e394",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cfd_to_vectors(cfd):\n",
    "    # We put our rows and columns in order.\n",
    "    # For now, our rows are the same as our columns:\n",
    "    # All target words are also context words, and vice versa.\n",
    "    # But that doesn't have to be the case.\n",
    "    targetlist = sorted(cfd.conditions())\n",
    "    contextlist = sorted(list(set(c for t in cfd.conditions() \n",
    "                                  for c in cfd[t].keys())))\n",
    "\n",
    "    # make a numpy matrix out of our sparse dictionary entries\n",
    "    rows = {}\n",
    "    \n",
    "    for t in targetlist:\n",
    "        # for context words c for which we don't have an entry,\n",
    "        # the ConditionalFreqDist returns zero\n",
    "        rows[t] = ( np.array( [cfd[t][c] for c in contextlist] ))\n",
    "\n",
    "    #count_matrix = np.array(rows)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a8237d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use it to convert our sparse representations to numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a364933",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vectors = cfd_to_vectors(cfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deba24a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['go']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790687d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now compare two words using cosine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e469fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Python has a built-in function for cosine -- with one catch: It computes 1 - cosine, as a distance. Here's how to get back to cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d014add",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    \"\"\"\n",
    "    vec1 and vec2 are Numpy vectors\n",
    "    \"\"\"\n",
    "    return 1 - scipy.spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940411a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: how do we calculate the cosine similarity of 'drink' and 'all' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd3d9d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b0048",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about the similarity of 'drink' and 'play'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa35ded",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddeabff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From word co-occurrence counts to association weights\n",
    "\n",
    "As we discussed in class, raw frequency counts may not be what we want -- we don't need to know that all words co-occur a lot with \"the\" and \"a\". Even if we ditch stopwords, the frequency bias in the data may not be what we want: Do we need to know that all words co-occur a lot with \"said\"? \n",
    "\n",
    "Several methods have been developed for going from counts to association weights, including tf/idf and pointwise mutual information. Here, we demonstrate how to compute pointwise mutual information, defined as\n",
    "\n",
    "$PMI(a, b) = \\log \\frac{P(a, b)}{P(a)P(b)}$ \n",
    "\n",
    "In the numerator, we have the joint probability of a *and* b. The formula compares this to the denominator, which has the product of the probability of a and the probability of b: If a and b were completely independent, had zero association, we would expect them to co-occur only by chance, that is, we would expect $P(a, b) = P(a)P(b)$. If $P(a, b)$ is larger than $P(a)P(b)$, then a and b are positively associated -- they co-occur more often than you would expect just from chance encounters. If $P(a, b)$ is smaller than $P(a)P(b)$, then a and b are negatively associated -- they really don't want to go together. \n",
    "\n",
    "In practice, we are often not interested in negative associations, and only use positive ones. Then we get PPMI:\n",
    "\n",
    "\n",
    "$PPMI(a, b) = \\left\\{\\begin{array}{ll}PMI(a, b) & \\text{if } PMI(a, b) > 0\\\\\n",
    "0 & \\text{else}\n",
    "\\end{array}\\right.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21bb9b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Homework: Transform the co-occurence count matrix into an association matrix using PPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbdbac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The easiest way to do this is to store our word vectors as a large matrix (a 2 dimensional array), and perform operations on this. Here is a function that converts a cfd into a numpy matrix. It also returns two dictionaries that help us get the labels of the rows and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96f1f85b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cfd_to_matrix_and_label_lookups(cfd):\n",
    "    targetlist = sorted(cfd.conditions())\n",
    "    contextlist = sorted(list(set(c for t in cfd.conditions() \n",
    "                                  for c in cfd[t].keys())))\n",
    "    rows = [ ]\n",
    "    for t in targetlist:\n",
    "        # for context words c for which we don't have an entry,\n",
    "        # the ConditionalFreqDist returns zero\n",
    "        rows.append( [cfd[t][c] for c in contextlist])\n",
    "\n",
    "    count_matrix = np.array(rows)\n",
    "\n",
    "    # and now we make a dictionary to look up rows by target word\n",
    "    target_dict = { }\n",
    "    for index, target in enumerate(targetlist):\n",
    "        target_dict[target] = index\n",
    "\n",
    "    # and now we make a dictionary to look up columns by context word\n",
    "    context_dict = { }\n",
    "    for index, context in enumerate(contextlist):\n",
    "        context_dict[context] = index\n",
    "    \n",
    "    return count_matrix, target_dict, context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a20727c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "count_matrix, target_dict, context_dict = cfd_to_matrix_and_label_lookups(cfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0910",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the information you'll need:\n",
    "\n",
    "Formula for pointwise mutual information (PMI)\n",
    "\n",
    "$PMI(t, c) = log \\frac{P(target, context)}{P(target) P(context)}$\n",
    "\n",
    "Definitions of different sums\n",
    "```\n",
    "   #(t, c): the co-occurrence count of t with c\n",
    "   #(_, _): the sum of counts in the whole table, across all targets\n",
    "   #(t, _): the sum of counts in the row of target t\n",
    "   #(_, c): the sum of counts in the column of context item c\n",
    "```\n",
    "\n",
    "Formula expressions in terms of these sums\n",
    "```\n",
    "    P(t, c) = #(t, c) / #(_, _)\n",
    "    P(t) = #(t, _) / #(_, _)\n",
    "    P(c) = #(_, c) / #(_, _)\n",
    "```\n",
    "and finally\n",
    "```\n",
    "PPMI(t, c) = { PMI(t, c) if PMI(t, c) >= 0\n",
    "               0, else\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0243194a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target count for one 3\n",
      "overall count 70\n",
      "context item count for drink 2\n"
     ]
    }
   ],
   "source": [
    "# target count #(t, _):\n",
    "print(\"target count for one\", count_matrix[ target_dict[\"one\"]].sum())\n",
    "\n",
    "# overall count #(_, _):\n",
    "print(\"overall count\", count_matrix.sum())\n",
    "\n",
    "# context item count #(_, c):\n",
    "print(\"context item count for drink\", count_matrix[ :, context_dict[\"drink\"]].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c7a6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Your code should take `count_matrix` and transform it into a matrix with PPMI weighted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36120101",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Start with the big matrix we made and  transform it to a matrix with PPMI weighted values\n",
    "\n",
    "#\n",
    "# do stuff here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda8b0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Having a large number of dimensions in the feature space can mean that the volume of that space is very large, and in turn, the points that we have in that space (rows of data) often represent a small and non-representative sample.\n",
    "\n",
    "This can dramatically impact the performance of machine learning algorithms fit on data with many input features, generally referred to as the “curse of dimensionality.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bd8c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our data are very sparse. The vectors are mostly zeros witha few nonzero values. SVD is the technique of choice for sparse data.\n",
    "\n",
    "Principal Components Analysis (PCA) is super common as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe17908f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "# Principal component analysis\n",
    "\n",
    "pcaobj = PCA()\n",
    "pca_matrix = pcaobj.fit_transform(count_matrix)\n",
    "# and let's actually reduce dimensionality\n",
    "keep_this_many_dimensions = 10\n",
    "pca_matrix = pca_matrix[:, :keep_this_many_dimensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46792759",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a utility function to turn a matrix into a dataframe. use this if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64da7dea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_to_dataframe(count_matrix, target_dict, context_dict):\n",
    "    \n",
    "    # We put our rows and columns in order.\n",
    "    # For now, our rows are the same as our columns:\n",
    "    # All target words are also context words, and vice versa.\n",
    "    # But that doesn't have to be the case.\n",
    "    targetlist = sorted(cfd.conditions())\n",
    "    contextlist = sorted(list(set(c for t in cfd.conditions() \n",
    "                                  for c in cfd[t].keys())))\n",
    "\n",
    "    # make a numpy matrix out of our sparse dictionary entries\n",
    "    rows = [ ]\n",
    "    for t in targetlist:\n",
    "        # for context words c for which we don't have an entry,\n",
    "        # the ConditionalFreqDist returns zero\n",
    "        rows.append( [cfd[t][c] for c in contextlist])\n",
    "\n",
    "    count_matrix = np.array(rows)\n",
    "    count_matrix\n",
    "\n",
    "    # add a space so that pandas doesn't get confused that our rows and columns have the same name\n",
    "    contextlist1 = [w+ \" \" for w in contextlist] \n",
    "    \n",
    "    # make the pandas dataframe\n",
    "    df =  pd.DataFrame.from_records(data=count_matrix, index=targetlist, columns = [c+\" \" for c in contextlist1])\n",
    "    df.index.name = 'target'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7a23a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we compute similarity again, the absolute value of the cosine similarity is different! -- Absolute similarity values can vary widely across the original and dimensionality-reduced spaces, but they will probably still predict the same nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "929695be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953539509042691"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and computing similarity again\n",
    "\n",
    "cosine_sim( pca_matrix[target_dict['drink']], pca_matrix[target_dict['play']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d7c1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An aside: Nearest Neighbors\n",
    "\n",
    "We want to know about a word's nearest neighbors. Computing this by hand is a major pain: You would have to compute all pairwise cosines, and then rummage through them to find the maximum. In our tiny corpus, this is feasible, but not in a large corpus. Fortunatly scikit-learn has a function NearestNeighbors that can do the work for us. One downside: It does not know cosine similarity outright. \n",
    "\n",
    "First option: We give it the cosine distance function that we used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419e1413",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&lt;function cosine at 0x10d6e40e0&gt;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&lt;function cosine at 0x10d6e40e0&gt;, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric=<function cosine at 0x10d6e40e0>, n_neighbors=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we make a nearest-neighbors object and tell it we'll always want the 3 nearest neighbors at a time\n",
    "nearest_neighbors_obj = NearestNeighbors(n_neighbors=3, metric = scipy.spatial.distance.cosine)\n",
    "\n",
    "# we then allow it to compute an internal datastructure from our data\n",
    "nearest_neighbors_obj.fit(pca_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db90222b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cosine_distances, target_indices = nearest_neighbors_obj.kneighbors([pca_matrix[target_dict[\"us\"]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8188a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`cosine_distances` and `target_indices` are both two-dimensional arrays. Let's extract  lists of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8426e1a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor is us with similarity 1.0\n",
      "Neighbor is all with similarity 0.316358691133761\n",
      "Neighbor is did with similarity 0.01736892319791339\n"
     ]
    }
   ],
   "source": [
    "## this block prints out the nearest neighbors of the word we select in the previous block\n",
    "\n",
    "target_list = sorted(target_dict.keys())\n",
    "\n",
    "cosine_distances = cosine_distances[0].tolist()\n",
    "target_indices = target_indices[0].tolist()\n",
    "\n",
    "for cosinedist, targetindex in zip(cosine_distances, target_indices):\n",
    "    print(\"Neighbor is\", target_list[targetindex], \"with similarity\", 1 - cosinedist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b4632",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise: What are the 4 closest neighbors of drink?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "111114f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Do your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4ffd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural networks are actually just the same thing\n",
    "\n",
    "<img src=\"../img/implicit.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee3ea4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So: Why not just do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8a756",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creative Writing with the vectorized word\n",
    "\n",
    "This lesson has been about taking relationships of form and turning them into relations about meaning using  vector spaces  (they are called semantic spaces for a reason).\n",
    "\n",
    "In this project, Allison parrish turns the concept on its head by using it to organize form rather than meaning. \n",
    "\n",
    "https://www.youtube.com/watch?v=L3D0JEA1Jdc&t=2055s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911c8d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question: How else could we imagine context???\n",
    "\n",
    "potential projects???\n",
    "\n",
    "comparing semantic similarity."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
